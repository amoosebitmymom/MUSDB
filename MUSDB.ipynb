{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MUSDB.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bGjbBWxSb9bl",
        "RmIQpXVgbcC7",
        "1RS6ck04cNIR",
        "DbVhDpfFbhH9"
      ],
      "toc_visible": true,
      "mount_file_id": "12nVTyonkoY1Lmb9xRsTO1ZMnaEVMfxQA",
      "authorship_tag": "ABX9TyMt8gaSK8bR2hb/foNApjvI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amoosebitmymom/MUSDB/blob/main/MUSDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metadata\n"
      ],
      "metadata": {
        "id": "bGjbBWxSb9bl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "consists of information necessary for the exection of the program, must always be run before doing changes in the code"
      ],
      "metadata": {
        "id": "XFEjHh0XBtD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeKceoTWTxsI",
        "outputId": "5e0b44bf-061a-47c3-e7db-d292efa78eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting musdb\n",
            "  Downloading musdb-0.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from musdb) (1.19.5)\n",
            "Collecting stempeg>=0.2.3\n",
            "  Downloading stempeg-0.2.3-py3-none-any.whl (963 kB)\n",
            "\u001b[K     |████████████████████████████████| 963 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from musdb) (4.62.3)\n",
            "Collecting pyaml\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting ffmpeg-python>=0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (0.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml->musdb) (3.13)\n",
            "Installing collected packages: ffmpeg-python, stempeg, pyaml, musdb\n",
            "Successfully installed ffmpeg-python-0.2.0 musdb-0.4.0 pyaml-21.10.1 stempeg-0.2.3\n"
          ]
        }
      ],
      "source": [
        "\"\"\" installing the mudsb package, which includes 7 second song segments as stem files \"\"\"\n",
        "!pip install musdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import musdb\n",
        "import pickle\n",
        "import IPython\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa as lb\n",
        "import stempeg as sp\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib import cm\n",
        "from sklearn import metrics \n",
        "from librosa import display\n",
        "from IPython import display\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "metadata": {
        "id": "aCXeHJPfbAx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MUSDB 2018 Dataset <br>\n",
        "The musdb18 consists of 150 songs of different styles along with the images of<br> their constitutive objects.<br>\n",
        "\n",
        "musdb18 contains two folders, a folder with a training set: \"train\", composed <br>of 100 songs, and a folder with a test set: \"test\", composed of 50 songs. <br>Supervised approaches should be trained on the training set and tested on both<br> sets.\n",
        "\n",
        "All files from the musdb18 dataset are encoded in the Native Instruments stems <br>format (.mp4). It is a multitrack format composed of 5 stereo streams, each one<br> encoded in AAC @256kbps. These signals correspond to:<br>\n",
        "\n",
        "0 - The mixture,<br>\n",
        "1 - The drums,<br>\n",
        "2 - The bass,<br>\n",
        "3 - The rest of the accompaniment,<br>\n",
        "4 - The vocals.<br>\n",
        "\n",
        "For each file, the mixture correspond to the sum of all the signals. All <br>signals are stereophonic and encoded at 44.1kHz.<br>\n",
        "\n",
        "The data from musdb18 is composed of several different sources:\n",
        "\n",
        "100 tracks are taken from the DSD100 dataset, which is itself derived from The<br> 'Mixing Secrets' Free Multitrack Download Library. Please refer to this <br>original resource for any question regarding your rights on your use of the <br>DSD100 data.<br>\n",
        "\n",
        "46 tracks are taken from the MedleyDB licensed under Creative Commons (BY-NC-SA 4.0).<br>\n",
        "\n",
        "2 tracks were kindly provided by Native Instruments originally part of their stems pack.<br>\n",
        "\n",
        "2 tracks a from from the Canadian rock band The Easton Ellises as part of the <br>heise stems remix competition, licensed under Creative Commons (BY-NC-SA 3.0).\n",
        "\n"
      ],
      "metadata": {
        "id": "K3xmGFgMcGCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "a list of all the song names in the dataset -\n",
        "0 - 99: train folder\n",
        "100 - 149 : test folder \n",
        "\"\"\"\n",
        "song_names = [\n",
        "\"A Classic Education - NightOwl.stem\",\n",
        "\"Actions - Devil's Words.stem\",\n",
        "\"Actions - One Minute Smile.stem\",\n",
        "\"Actions - South Of The Water.stem\",\n",
        "\"Aimee Norwich - Child.stem\",\n",
        "\"Alexander Ross - Goodbye Bolero.stem\",\n",
        "\"Alexander Ross - Velvet Curtain.stem\",\n",
        "\"Angela Thomas Wade - Milk Cow Blues.stem\",\n",
        "\"ANiMAL - Clinic A.stem\",\n",
        "\"ANiMAL - Easy Tiger.stem\",\n",
        "\"ANiMAL - Rockshow.stem\",\n",
        "\"Atlantis Bound - It Was My Fault For Waiting.stem\",\n",
        "\"Auctioneer - Our Future Faces.stem\",\n",
        "\"AvaLuna - Waterduct.stem\",\n",
        "\"BigTroubles - Phantom.stem\",\n",
        "\"Bill Chudziak - Children Of No-one.stem\",\n",
        "\"Black Bloc - If You Want Success.stem\",\n",
        "\"Celestial Shore - Die For Us.stem\",\n",
        "\"Chris Durban - Celebrate.stem\",\n",
        "\"Clara Berry And Wooldog - Air Traffic.stem\",\n",
        "\"Clara Berry And Wooldog - Stella.stem\",\n",
        "\"Clara Berry And Wooldog - Waltz For My Victims.stem\",\n",
        "\"Cnoc An Tursa - Bannockburn.stem\",\n",
        "\"Creepoid - OldTree.stem\",\n",
        "\"Dark Ride - Burning Bridges.stem\",\n",
        "\"Dreamers Of The Ghetto - Heavy Love.stem\",\n",
        "\"Drumtracks - Ghost Bitch.stem\",\n",
        "\"Faces On Film - Waiting For Ga.stem\",\n",
        "\"Fergessen - Back From The Start.stem\",\n",
        "\"Fergessen - Nos Palpitants.stem\",\n",
        "\"Fergessen - The Wind.stem\",\n",
        "\"Flags - 54.stem\",\n",
        "\"Giselle - Moss.stem\",\n",
        "\"Grants - PunchDrunk.stem\",\n",
        "\"Helado Negro - Mitad Del Mundo.stem\",\n",
        "\"Hezekiah Jones - Borrowed Heart.stem\",\n",
        "\"Hollow Ground - Left Blind.stem\",\n",
        "\"Hop Along - Sister Cities.stem\",\n",
        "\"Invisible Familiars - Disturbing Wildlife.stem\",\n",
        "\"James May - All Souls Moon.stem\",\n",
        "\"James May - Dont Let Go.stem\",\n",
        "\"James May - If You Say.stem\",\n",
        "\"James May - On The Line.stem\",\n",
        "\"Jay Menon - Through My Eyes.stem\",\n",
        "\"Johnny Lokke - Promises & Lies.stem\",\n",
        "\"Johnny Lokke - Whisper To A Scream.stem\",\n",
        "\"Jokers, Jacks & Kings - Sea Of Leaves.stem\",\n",
        "\"Leaf - Come Around.stem\",\n",
        "\"Leaf - Summerghost.stem\",\n",
        "\"Leaf - Wicked.stem\",\n",
        "\"Lushlife - Toynbee Suite.stem\",\n",
        "\"Matthew Entwistle - Dont You Ever.stem\",\n",
        "\"Meaxic - Take A Step.stem\",\n",
        "\"Meaxic - You Listen.stem\",\n",
        "\"Music Delta - 80s Rock.stem\",\n",
        "\"Music Delta - Beatles.stem\",\n",
        "\"Music Delta - Britpop.stem\",\n",
        "\"Music Delta - Country1.stem\",\n",
        "\"Music Delta - Country2.stem\",\n",
        "\"Music Delta - Disco.stem\",\n",
        "\"Music Delta - Gospel.stem\",\n",
        "\"Music Delta - Grunge.stem\",\n",
        "\"Music Delta - Hendrix.stem\",\n",
        "\"Music Delta - Punk.stem\",\n",
        "\"Music Delta - Reggae.stem\",\n",
        "\"Music Delta - Rock.stem\",\n",
        "\"Music Delta - Rockabilly.stem\",\n",
        "\"Night Panther - Fire.stem\",\n",
        "\"North To Alaska - All The Same.stem\",\n",
        "\"Patrick Talbot - A Reason To Leave.stem\",\n",
        "\"Patrick Talbot - Set Me Free.stem\",\n",
        "\"Phre The Eon - Everybody's Falling Apart.stem\",\n",
        "\"Port St Willow - Stay Even.stem\",\n",
        "\"Remember December - C U Next Time.stem\",\n",
        "\"Secret Mountains - High Horse.stem\",\n",
        "\"Skelpolu - Human Mistakes.stem\",\n",
        "\"Skelpolu - Together Alone.stem\",\n",
        "\"Snowmine - Curfews.stem\",\n",
        "\"Spike Mullings - Mike's Sulking.stem\",\n",
        "\"St Vitus - Word Gets Around.stem\",\n",
        "\"Steven Clark - Bounty.stem\",\n",
        "\"Strand Of Oaks - Spacestation.stem\",\n",
        "\"Sweet Lights - You Let Me Down.stem\",\n",
        "\"Swinging Steaks - Lost My Way.stem\",\n",
        "\"The Districts - Vermont.stem\",\n",
        "\"The Long Wait - Back Home To Blue.stem\",\n",
        "\"The Scarlet Brand - Les Fleurs Du Mal.stem\",\n",
        "\"The So So Glos - Emergency.stem\",\n",
        "\"The Wrong'Uns - Rothko.stem\",\n",
        "\"Tim Taler - Stalker.stem\",\n",
        "\"Titanium - Haunted Age.stem\",\n",
        "\"Traffic Experiment - Once More (With Feeling).stem\",\n",
        "\"Traffic Experiment - Sirens.stem\",\n",
        "\"Triviul - Angelsaint.stem\",\n",
        "\"Triviul - Dorothy.stem\",\n",
        "\"Voelund - Comfort Lives In Belief.stem\",\n",
        "\"Wall Of Death - Femme.stem\",\n",
        "\"Young Griffo - Blood To Bone.stem\",\n",
        "\"Young Griffo - Facade.stem\",\n",
        "\"Young Griffo - Pennies.stem\",\n",
        "\n",
        "\n",
        "\"Al James - Schoolboy Facination.stem\",\n",
        "\"AM Contra - Heart Peripheral.stem\",\n",
        "\"Angels In Amplifiers - I'm Alright.stem\",\n",
        "\"Arise - Run Run Run.stem\",\n",
        "\"Ben Carrigan - We'll Talk About It All Tonight.stem\",\n",
        "\"BKS - Bulldozer.stem\",\n",
        "\"BKS - Too Much.stem\",\n",
        "\"Bobby Nobody - Stitch Up.stem\",\n",
        "\"Buitraker - Revo X.stem\",\n",
        "\"Carlos Gonzalez - A Place For Us.stem\",\n",
        "\"Cristina Vane - So Easy.stem\",\n",
        "\"Detsky Sad - Walkie Talkie.stem\",\n",
        "\"Enda Reilly - Cur An Long Ag Seol.stem\",\n",
        "\"Forkupines - Semantics.stem\",\n",
        "\"Georgia Wonder - Siren.stem\",\n",
        "\"Girls Under Glass - We Feel Alright.stem\",\n",
        "\"Hollow Ground - Ill Fate.stem\",\n",
        "\"James Elder & Mark M Thompson - The English Actor.stem\",\n",
        "\"Juliet's Rescue - Heartbeats.stem\",\n",
        "\"Little Chicago's Finest - My Own.stem\",\n",
        "\"Louis Cressy Band - Good Time.stem\",\n",
        "\"Lyndsey Ollard - Catching Up.stem\",\n",
        "\"M.E.R.C. Music - Knockout.stem\",\n",
        "\"Moosmusic - Big Dummy Shake.stem\",\n",
        "\"Motor Tapes - Shore.stem\",\n",
        "\"Mu - Too Bright.stem\",\n",
        "\"Nerve 9 - Pray For The Rain.stem\",\n",
        "\"PR - Happy Daze.stem\",\n",
        "\"PR - Oh No.stem\",\n",
        "\"Punkdisco - Oral Hygiene.stem\",\n",
        "\"Raft Monk - Tiring.stem\",\n",
        "\"Sambasevam Shanmugam - Kaathaadi.stem\",\n",
        "\"Secretariat - Borderline.stem\",\n",
        "\"Secretariat - Over The Top.stem\",\n",
        "\"Side Effects Project - Sing With Me.stem\",\n",
        "\"Signe Jakobsen - What Have You Done To Me.stem\",\n",
        "\"Skelpolu - Resurrection.stem\",\n",
        "\"Speak Softly - Broken Man.stem\",\n",
        "\"Speak Softly - Like Horses.stem\",\n",
        "\"The Doppler Shift - Atrophy.stem\",\n",
        "\"The Easton Ellises - Falcon 69.stem\",\n",
        "\"The Easton Ellises (Baumi) - SDRNR.stem\",\n",
        "\"The Long Wait - Dark Horses.stem\",\n",
        "\"The Mountaineering Club - Mallory.stem\",\n",
        "\"The Sunshine Garcia Band - For I Am The Moon.stem\",\n",
        "\"Timboz - Pony.stem\",\n",
        "\"Tom McKenzie - Directions.stem\",\n",
        "\"Triviul feat. The Fiend - Widow.stem\",\n",
        "\"We Fell From The Sky - Not You.stem\",\n",
        "\"Zeno - Signs.stem\"\n",
        "]"
      ],
      "metadata": {
        "id": "RPg0-O7qRgNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Data/MUSDB/\" # basic directory, which includes two folders (train, test) and within them the songs "
      ],
      "metadata": {
        "id": "r74svJVycQ6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data downloading"
      ],
      "metadata": {
        "id": "RmIQpXVgbcC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "downloads the song segments, no need to run because they are saved on google drive"
      ],
      "metadata": {
        "id": "a_nBJZ8hBmMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mus = musdb.DB(root=\"/content/drive/MyDrive/Data/MUSDB\", download=True) "
      ],
      "metadata": {
        "id": "lStIYlWnUM0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data verification"
      ],
      "metadata": {
        "id": "1RS6ck04cNIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "verifys all the data exists and seprates the data into its corresponding folders"
      ],
      "metadata": {
        "id": "QyPOWIy0B6Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "a function which checks if a given file exists. If it does not, it saves its name\n",
        "\n",
        "path = the basic directory of all the files\n",
        "folder = the folder where the file is found\n",
        "names = a list consisting of all the file names we want to check\n",
        "\n",
        "returns the list of all the missing files\n",
        "\"\"\"\n",
        "def file_not_found(path, folder, names):\n",
        "  full_path = path + folder + '/'\n",
        "\n",
        "  files_missing = []\n",
        "\n",
        "  for i in range(len(names)):\n",
        "    file_path = full_path + names[i] + '.mp4' # each files ends with a .mp4\n",
        "    if(not os.path.isfile(file_path)):\n",
        "      files_missing.append(names[i])\n",
        "\n",
        "  return files_missing"
      ],
      "metadata": {
        "id": "KRgJ6BPXcsAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_missing_train = file_not_found(path, 'train', song_names[0: 100]) # checks if there are files missing in the train folder"
      ],
      "metadata": {
        "id": "8mHIqDs5dp1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_missing_test = file_not_found(path, 'test', song_names[100: 149]) # checks if there are files missing in the test folder"
      ],
      "metadata": {
        "id": "TcrMo7zfeTTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(files_missing_train)\n",
        "print(files_missing_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBN5eeToeXvl",
        "outputId": "d0bce698-72ec-4277-f36f-5f4da252e6e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Music Delta - Country2.stem', 'Music Delta - Hendrix.stem', 'Music Delta - Punk.stem', 'Music Delta - Reggae.stem', 'Music Delta - Rock.stem', 'Music Delta - Rockabilly.stem']\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "a function which gets a list of names and a list of files, and removes the files from the list of names\n",
        "\n",
        "names = a list with names of files\n",
        "files = a list with files to be removed from 'names'\n",
        "\n",
        "return names with the files removed\n",
        "\"\"\"\n",
        "def name_remove(names, files):\n",
        "  for i in range(len(files)):\n",
        "    names.remove(files[i])\n",
        "  return names"
      ],
      "metadata": {
        "id": "gr7ezYYeeysi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_song_names = song_names[0:100] # all the files in the train folder\n",
        "train_song_names = name_remove(train_song_names, files_missing_train) # removes the missing files\n",
        "print(len(train_song_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iwKeLDJep6t",
        "outputId": "b12689ff-be54-4879-ab4b-fa3eb36d2da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_song_names = song_names[100:150] # all the files in the test folder"
      ],
      "metadata": {
        "id": "Qhg0FtlafL2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data augmentation"
      ],
      "metadata": {
        "id": "DbVhDpfFbhH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loads the data into 0.6 segments, converts it to mono and turns into numpy array"
      ],
      "metadata": {
        "id": "EiqEt2RmCKi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "a function which gets a stem file path and returns the file deconstructed \n",
        "\n",
        "file_name = the file path to load\n",
        "\n",
        "returns the file cut into 0.6 seconds segments\n",
        "\"\"\"\n",
        "def decoding_stems(file_name):\n",
        "  audio, sr = sp.read_stems(file_name, sample_rate=22050)\n",
        "  \n",
        "  swap_ad = np.swapaxes(audio, 1 , 2) # swaps the first and second axis because most libraries execpt num channels in the second axis and the data in the first\n",
        "\n",
        "  duration = lb.get_duration(swap_ad[1])\n",
        "  \n",
        "  duration_length = (duration // 0.6) * 6 # rounds the song duration to be divisilbe by 6 so that each sound segment is in equal length\n",
        "\n",
        "  return stft_frame(file_name, int(duration_length), 6)"
      ],
      "metadata": {
        "id": "ViXYpbI2fX-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "a function which gets stem file duration and cuts it into 0.6 seconds segments\n",
        "\n",
        "path = the file path to load\n",
        "song_duration = how long the stem file is\n",
        "ld_time = how long each segment should be\n",
        "\n",
        "returns each segments in a list, after converting to a mono stream\n",
        "\"\"\"\n",
        "def stft_frame(path, song_duration, ld_time):\n",
        "  frames = []\n",
        "\n",
        "  for i in range(0, song_duration, ld_time):\n",
        "    y, sr = sp.read_stems(path, sample_rate=22050, start=(i / 10), duration=ld_time / 10)  # divides by 10 because you can't loop floats, so we loop with 6 and divide by 10 to get the desired length\n",
        "\n",
        "    y_swap = np.swapaxes(y, 1, 2)  # swaps the first and second axis because most libraries execpt num channels in the second axis and the data in the first\n",
        "    frames.append(y_swap)\n",
        "\n",
        "  return stereo_to_mono(frames)"
      ],
      "metadata": {
        "id": "qPsqdv6DirQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "a fucntion which gets a list of stereo audio files, and returns each file a a mono \n",
        "\n",
        "stereo - a list consisting of stereo audio files\n",
        "\n",
        "returns each audio files a mono\n",
        "\"\"\"\n",
        "def stereo_to_mono(stereo):\n",
        "  mono_frames = []\n",
        "\n",
        "  for i in range(len(stereo)):\n",
        "    mono_file = []\n",
        "\n",
        "    for j in range(len(stereo[i])):\n",
        "      mono = lb.to_mono(stereo[i][j])\n",
        "      mono_file.append(mono)\n",
        "\n",
        "    mono_frames.append(mono_file)\n",
        "\n",
        "  return mono_frames"
      ],
      "metadata": {
        "id": "txbVHrEqt40N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "decodes each stem file in the train folder\n",
        "\"\"\"\n",
        "train_audio_data = []\n",
        "\n",
        "for i in range(len(train_song_names)):\n",
        "  \n",
        "  file_path = path + 'train/' + train_song_names[i] + '.mp4'\n",
        "  audio_seg = decoding_stems(file_path)\n",
        "  \n",
        "  train_audio_data.append(audio_seg)"
      ],
      "metadata": {
        "id": "SZ7C5VVmiUsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "decodes each stem file in the train folder\n",
        "\"\"\"\n",
        "test_audio_data = []\n",
        "\n",
        "for i in range(len(test_song_names)):\n",
        "  \n",
        "  file_path = path + 'test/' + test_song_names[i] + '.mp4'\n",
        "  audio_seg = decoding_stems(file_path)\n",
        "  \n",
        "  test_audio_data.append(audio_seg)"
      ],
      "metadata": {
        "id": "ScVEwLA4BRo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"converting the audio lists into numpu arrays\"\"\"\n",
        "train_audio_data = np.array(train_audio_data)\n",
        "test_audio_data = np.array(test_audio_data)"
      ],
      "metadata": {
        "id": "sw-jIyQv2IJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_audio_data.shape)\n",
        "print(test_audio_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyMZVE0h2Lek",
        "outputId": "c4ab8273-d837-4002-c111-9be264a23ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(94, 11, 5, 13230)\n",
            "(50, 11, 5, 13230)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataframe creation"
      ],
      "metadata": {
        "id": "45sWZ6x32c-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "consolodates the information into a pandas dataframe and pickels it for future use"
      ],
      "metadata": {
        "id": "RMaxKUXoCSlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "a function which creates a dataframe row with given data\n",
        "\n",
        "file_name = the name of the audio file\n",
        "data = the data, which is a list of length = 5, each consisting of a different sound part\n",
        "folder = what folder the file is in\n",
        "start = in what time does the segment start in the original sound file\n",
        "end = in what time does the segment end in the original sound file\n",
        "\n",
        "returns a dataframe row of the data\n",
        "\"\"\"\n",
        "def df_add(file_name, data, folder, start, end):\n",
        "  return pd.DataFrame({0: file_name, 1: [data[0]], 2: [data[1]], 3: [data[2]], 4: [data[3]], 5: [data[4]], 6: folder, 7: start, 8: end})"
      ],
      "metadata": {
        "id": "1DuFBd4hj8Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "makes a dataframe with each row corresponding to a different sound segment in the train folder\n",
        "\"\"\"\n",
        "df_train = pd.DataFrame()\n",
        "for i in range(len(train_audio_data)):\n",
        "  duration = 0\n",
        "  for j in range(len(train_audio_data[i])):\n",
        "    df_train = df_train.append(df_add(train_song_names[i], train_audio_data[i][0], 'train', duration, duration+0.6), ignore_index=True, verify_integrity=True)\n",
        "    duration = duration + 0.6"
      ],
      "metadata": {
        "id": "AWuq_EMK4BW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "makes a dataframe with each row corresponding to a different sound segment in the test folder\n",
        "\"\"\"\n",
        "df_test = pd.DataFrame()\n",
        "for i in range(len(test_audio_data)):\n",
        "  duration = 0\n",
        "  for j in range(len(test_audio_data[i])):\n",
        "    df_test = df_test.append(df_add(test_song_names[i], test_audio_data[i][0], 'test', duration, duration+0.6), ignore_index=True, verify_integrity=True)\n",
        "    duration = duration + 0.6"
      ],
      "metadata": {
        "id": "fRswUdu244QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "concetrates the two dataframe into one coherent dataframe\n",
        "\"\"\"\n",
        "df_data = pd.concat([df_train, df_test], ignore_index=True, verify_integrity=True)"
      ],
      "metadata": {
        "id": "g9Vtu43jmoP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.info(memory_usage='deep') # memory data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn5dFE69oD8a",
        "outputId": "8b82d41f-7ff4-4471-bbb9-b938c035d19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1584 entries, 0 to 1583\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       1584 non-null   object \n",
            " 1   1       1584 non-null   object \n",
            " 2   2       1584 non-null   object \n",
            " 3   3       1584 non-null   object \n",
            " 4   4       1584 non-null   object \n",
            " 5   5       1584 non-null   object \n",
            " 6   6       1584 non-null   object \n",
            " 7   7       1584 non-null   float64\n",
            " 8   8       1584 non-null   float64\n",
            "dtypes: float64(2), object(7)\n",
            "memory usage: 1.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = df_data.rename(columns={0: 'song_name', 1:'mixture', 2:'drums', 3:'bass', 4:'accompaniment', 5:'vocals', 6:'folder' , 7: 'start', 8:'end'}) # renaming the columns\n",
        "df_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "HoTYqYR3pi4z",
        "outputId": "582d084d-6ec3-4dec-cb39-844e4c8cbbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_name</th>\n",
              "      <th>mixture</th>\n",
              "      <th>drums</th>\n",
              "      <th>bass</th>\n",
              "      <th>accompaniment</th>\n",
              "      <th>vocals</th>\n",
              "      <th>folder</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A Classic Education - NightOwl.stem</td>\n",
              "      <td>[-0.0715077668428421, -0.07427260838449001, -0...</td>\n",
              "      <td>[0.004260942805558443, 0.0010138616780750453, ...</td>\n",
              "      <td>[-0.05491206608712673, -0.05861355736851692, -...</td>\n",
              "      <td>[0.0027123100589960814, 0.0035784956999123096,...</td>\n",
              "      <td>[-0.02593752136453986, -0.022312448360025883, ...</td>\n",
              "      <td>train</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A Classic Education - NightOwl.stem</td>\n",
              "      <td>[-0.0715077668428421, -0.07427260838449001, -0...</td>\n",
              "      <td>[0.004260942805558443, 0.0010138616780750453, ...</td>\n",
              "      <td>[-0.05491206608712673, -0.05861355736851692, -...</td>\n",
              "      <td>[0.0027123100589960814, 0.0035784956999123096,...</td>\n",
              "      <td>[-0.02593752136453986, -0.022312448360025883, ...</td>\n",
              "      <td>train</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A Classic Education - NightOwl.stem</td>\n",
              "      <td>[-0.0715077668428421, -0.07427260838449001, -0...</td>\n",
              "      <td>[0.004260942805558443, 0.0010138616780750453, ...</td>\n",
              "      <td>[-0.05491206608712673, -0.05861355736851692, -...</td>\n",
              "      <td>[0.0027123100589960814, 0.0035784956999123096,...</td>\n",
              "      <td>[-0.02593752136453986, -0.022312448360025883, ...</td>\n",
              "      <td>train</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A Classic Education - NightOwl.stem</td>\n",
              "      <td>[-0.0715077668428421, -0.07427260838449001, -0...</td>\n",
              "      <td>[0.004260942805558443, 0.0010138616780750453, ...</td>\n",
              "      <td>[-0.05491206608712673, -0.05861355736851692, -...</td>\n",
              "      <td>[0.0027123100589960814, 0.0035784956999123096,...</td>\n",
              "      <td>[-0.02593752136453986, -0.022312448360025883, ...</td>\n",
              "      <td>train</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A Classic Education - NightOwl.stem</td>\n",
              "      <td>[-0.0715077668428421, -0.07427260838449001, -0...</td>\n",
              "      <td>[0.004260942805558443, 0.0010138616780750453, ...</td>\n",
              "      <td>[-0.05491206608712673, -0.05861355736851692, -...</td>\n",
              "      <td>[0.0027123100589960814, 0.0035784956999123096,...</td>\n",
              "      <td>[-0.02593752136453986, -0.022312448360025883, ...</td>\n",
              "      <td>train</td>\n",
              "      <td>2.4</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1579</th>\n",
              "      <td>Zeno - Signs.stem</td>\n",
              "      <td>[-0.006680804304778576, -0.08316835761070251, ...</td>\n",
              "      <td>[0.006809760816395283, 0.009227094938978553, 0...</td>\n",
              "      <td>[-0.036950407549738884, -0.0358741357922554, -...</td>\n",
              "      <td>[-0.009290379006415606, -0.02027385402470827, ...</td>\n",
              "      <td>[0.030881525948643684, -0.03163300175219774, -...</td>\n",
              "      <td>train</td>\n",
              "      <td>3.6</td>\n",
              "      <td>4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1580</th>\n",
              "      <td>Zeno - Signs.stem</td>\n",
              "      <td>[-0.006680804304778576, -0.08316835761070251, ...</td>\n",
              "      <td>[0.006809760816395283, 0.009227094938978553, 0...</td>\n",
              "      <td>[-0.036950407549738884, -0.0358741357922554, -...</td>\n",
              "      <td>[-0.009290379006415606, -0.02027385402470827, ...</td>\n",
              "      <td>[0.030881525948643684, -0.03163300175219774, -...</td>\n",
              "      <td>train</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1581</th>\n",
              "      <td>Zeno - Signs.stem</td>\n",
              "      <td>[-0.006680804304778576, -0.08316835761070251, ...</td>\n",
              "      <td>[0.006809760816395283, 0.009227094938978553, 0...</td>\n",
              "      <td>[-0.036950407549738884, -0.0358741357922554, -...</td>\n",
              "      <td>[-0.009290379006415606, -0.02027385402470827, ...</td>\n",
              "      <td>[0.030881525948643684, -0.03163300175219774, -...</td>\n",
              "      <td>train</td>\n",
              "      <td>4.8</td>\n",
              "      <td>5.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1582</th>\n",
              "      <td>Zeno - Signs.stem</td>\n",
              "      <td>[-0.006680804304778576, -0.08316835761070251, ...</td>\n",
              "      <td>[0.006809760816395283, 0.009227094938978553, 0...</td>\n",
              "      <td>[-0.036950407549738884, -0.0358741357922554, -...</td>\n",
              "      <td>[-0.009290379006415606, -0.02027385402470827, ...</td>\n",
              "      <td>[0.030881525948643684, -0.03163300175219774, -...</td>\n",
              "      <td>train</td>\n",
              "      <td>5.4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1583</th>\n",
              "      <td>Zeno - Signs.stem</td>\n",
              "      <td>[-0.006680804304778576, -0.08316835761070251, ...</td>\n",
              "      <td>[0.006809760816395283, 0.009227094938978553, 0...</td>\n",
              "      <td>[-0.036950407549738884, -0.0358741357922554, -...</td>\n",
              "      <td>[-0.009290379006415606, -0.02027385402470827, ...</td>\n",
              "      <td>[0.030881525948643684, -0.03163300175219774, -...</td>\n",
              "      <td>train</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1584 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                song_name  ...  end\n",
              "0     A Classic Education - NightOwl.stem  ...  0.6\n",
              "1     A Classic Education - NightOwl.stem  ...  1.2\n",
              "2     A Classic Education - NightOwl.stem  ...  1.8\n",
              "3     A Classic Education - NightOwl.stem  ...  2.4\n",
              "4     A Classic Education - NightOwl.stem  ...  3.0\n",
              "...                                   ...  ...  ...\n",
              "1579                    Zeno - Signs.stem  ...  4.2\n",
              "1580                    Zeno - Signs.stem  ...  4.8\n",
              "1581                    Zeno - Signs.stem  ...  5.4\n",
              "1582                    Zeno - Signs.stem  ...  6.0\n",
              "1583                    Zeno - Signs.stem  ...  6.6\n",
              "\n",
              "[1584 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.to_pickle(path='/content/drive/MyDrive/Data/MUSDB/df_data.pickle') # pickling the data"
      ],
      "metadata": {
        "id": "txMiPQ1ZH5Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction"
      ],
      "metadata": {
        "id": "2GY1qQkOrvUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = pd.read_pickle('/content/drive/MyDrive/Data/MUSDB/df_data.pickle')\n",
        "df_data.head()"
      ],
      "metadata": {
        "id": "X5c7IbdWIVL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transforming(y_vocals, y_mixture):\n",
        "  y_vocals = lb.stft(y_vocals, n_fft=2048, win_length=1024, hop_length=512)\n",
        "  y_mixture = lb.stft(y_mixture, n_fft=2048, win_length=1024, hop_length=512)\n",
        "\n",
        "  return y_vocals, y_mixture"
      ],
      "metadata": {
        "id": "Xr4GPpv_ydmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_vocals = []\n",
        "y_mixture = []\n",
        "for i in range(len(df_data)):\n",
        "  a = df_data.at[i, 'mixture']\n",
        "  b = df_data.at[i, 'vocals']\n",
        "\n",
        "  v, m = transforming(a, b)\n",
        "  y_vocals.append(v)\n",
        "  y_mixture.append(m)"
      ],
      "metadata": {
        "id": "mdO7JvILzNb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocals_stft = np.array(y_vocals)\n",
        "mixture_stft = np.array(y_mixture)"
      ],
      "metadata": {
        "id": "F9fQY84Sz6KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocals_stft.shape)\n",
        "print(mixture_stft.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_Op0dha0IPX",
        "outputId": "6c10c2d4-9f3f-41cc-a4ca-2c4d62a914c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1584, 1025, 26)\n",
            "(1584, 1025, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model preparation"
      ],
      "metadata": {
        "id": "c_zUYU8s1JBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocals_conv = np.reshape(vocals_stft, newshape=(1584, 1025, 26, 1))\n",
        "mixture_cov = np.reshape(mixture_stft, newshape=(1584, 1025, 26, 1))"
      ],
      "metadata": {
        "id": "PX2JcbzM5MJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', input_shape=(1025, 26, 1)))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Conv2D(16, (3,3), padding='same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Conv2D(16, (3,3), padding='same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(513))\n",
        "sgd = SGD(learning_rate=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=keras.losses.binary_crossentropy, optimizer=sgd, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4LMlCR-95BuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Be-gLGB79y0",
        "outputId": "40592667-c407-43fa-b222-40dfb3e64090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 1025, 26, 32)      320       \n",
            "                                                                 \n",
            " leaky_re_lu_20 (LeakyReLU)  (None, 1025, 26, 32)      0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 1025, 26, 16)      4624      \n",
            "                                                                 \n",
            " leaky_re_lu_21 (LeakyReLU)  (None, 1025, 26, 16)      0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 341, 8, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 341, 8, 16)        0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 341, 8, 64)        9280      \n",
            "                                                                 \n",
            " leaky_re_lu_22 (LeakyReLU)  (None, 341, 8, 64)        0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 341, 8, 16)        9232      \n",
            "                                                                 \n",
            " leaky_re_lu_23 (LeakyReLU)  (None, 341, 8, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 113, 2, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 113, 2, 16)        0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 3616)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               462976    \n",
            "                                                                 \n",
            " leaky_re_lu_24 (LeakyReLU)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 513)               66177     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 552,609\n",
            "Trainable params: 552,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}